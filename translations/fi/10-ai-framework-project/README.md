<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2c4ae5688e34b4b8b09d52aec56c79e",
  "translation_date": "2025-10-23T00:23:33+00:00",
  "source_file": "10-ai-framework-project/README.md",
  "language_code": "fi"
}
-->
# AI-kehys

Oletko koskaan tuntenut olevasi hukassa yritt√§ess√§si rakentaa teko√§lysovelluksia alusta alkaen? Et ole yksin! AI-kehykset ovat kuin monitoimity√∂kalu teko√§lykehitykseen ‚Äì tehokkaita ty√∂kaluja, jotka s√§√§st√§v√§t aikaa ja vaivaa √§lykk√§iden sovellusten rakentamisessa. Ajattele AI-kehyst√§ hyvin organisoituna kirjastona: se tarjoaa valmiiksi rakennettuja komponentteja, standardoituja API-rajapintoja ja √§lykk√§it√§ abstraktioita, jotta voit keskitty√§ ongelmien ratkaisemiseen sen sijaan, ett√§ kamppailisit toteutuksen yksityiskohtien kanssa.

T√§ss√§ oppitunnissa tutkimme, kuinka kehykset, kuten LangChain, voivat muuttaa aiemmin monimutkaiset teko√§lyn integrointiteht√§v√§t selke√§ksi ja helposti luettavaksi koodiksi. Opit ratkaisemaan todellisia haasteita, kuten keskustelujen seuraamista, ty√∂kalujen k√§ytt√∂√∂nottoa ja erilaisten teko√§lymallien hallintaa yhden yhten√§isen k√§ytt√∂liittym√§n kautta.

Kun oppitunti on ohi, tied√§t, milloin kannattaa valita kehykset raakojen API-kutsujen sijaan, kuinka k√§ytt√§√§ niiden abstraktioita tehokkaasti ja kuinka rakentaa teko√§lysovelluksia, jotka ovat valmiita todelliseen k√§ytt√∂√∂n. Tutkitaan, mit√§ AI-kehykset voivat tehd√§ projekteillesi.

## Miksi valita kehys?

Olet valmis rakentamaan teko√§lysovelluksen ‚Äì mahtavaa! Mutta t√§ss√§ on juttu: sinulla on useita eri polkuja, joita voit kulkea, ja jokaisella on omat hyv√§t ja huonot puolensa. Se on v√§h√§n kuin valitsisit k√§velyn, py√∂r√§ilyn tai ajamisen p√§√§st√§ksesi jonnekin ‚Äì kaikki viev√§t sinut perille, mutta kokemus (ja vaivann√§k√∂) on t√§ysin erilainen.

Katsotaanpa kolmea p√§√§asiallista tapaa integroida teko√§ly projekteihisi:

| L√§hestymistapa | Edut | Paras k√§ytt√∂ | Huomioitavaa |
|----------------|------|-------------|--------------|
| **Suorat HTTP-pyynn√∂t** | T√§ysi hallinta, ei riippuvuuksia | Yksinkertaiset kyselyt, perusteiden oppiminen | Paljon koodia, manuaalinen virheenk√§sittely |
| **SDK-integraatio** | V√§hemm√§n boilerplate-koodia, mallikohtainen optimointi | Yksitt√§ismalliset sovellukset | Rajoittuu tiettyihin tarjoajiin |
| **AI-kehykset** | Yhten√§inen API, sis√§√§nrakennetut abstraktiot | Monimalliset sovellukset, monimutkaiset ty√∂nkulut | Oppimisk√§yr√§, mahdollinen yliabstraktio |

### Kehyksen hy√∂dyt k√§yt√§nn√∂ss√§

```mermaid
graph TD
    A[Your Application] --> B[AI Framework]
    B --> C[OpenAI GPT]
    B --> D[Anthropic Claude]
    B --> E[GitHub Models]
    B --> F[Local Models]
    
    B --> G[Built-in Tools]
    G --> H[Memory Management]
    G --> I[Conversation History]
    G --> J[Function Calling]
    G --> K[Error Handling]
```

**Miksi kehykset ovat t√§rkeit√§:**
- **Yhdist√§√§** useita teko√§lypalveluntarjoajia yhteen k√§ytt√∂liittym√§√§n
- **K√§sittelee** keskustelumuistin automaattisesti
- **Tarjoaa** valmiita ty√∂kaluja yleisiin teht√§viin, kuten upotuksiin ja funktiokutsuihin
- **Hallinnoi** virheenk√§sittely√§ ja uudelleenkokeilulogiikkaa
- **Muuttaa** monimutkaiset ty√∂nkulut luettaviksi metodikutsuiksi

> üí° **Vinkki**: K√§yt√§ kehyksi√§, kun vaihdat eri teko√§lymallien v√§lill√§ tai rakennat monimutkaisia ominaisuuksia, kuten agentteja, muistia tai ty√∂kalujen k√§ytt√∂√§. Pysy suorissa API-kutsuissa, kun opettelet perusteita tai rakennat yksinkertaisia, keskittyneit√§ sovelluksia.

**Yhteenveto**: Kuten valinta erikoisty√∂kalujen ja t√§ydellisen ty√∂pajan v√§lill√§, kyse on ty√∂kalun sovittamisesta teht√§v√§√§n. Kehykset loistavat monimutkaisissa, ominaisuusrikkaissa sovelluksissa, kun taas suorat API:t toimivat hyvin yksinkertaisissa k√§ytt√∂tapauksissa.

## Johdanto

T√§ss√§ oppitunnissa opimme:

- K√§ytt√§m√§√§n yleist√§ AI-kehyst√§.
- Ratkaisemaan yleisi√§ ongelmia, kuten keskustelut, ty√∂kalujen k√§ytt√∂, muisti ja konteksti.
- Hy√∂dynt√§m√§√§n t√§t√§ teko√§lysovellusten rakentamiseen.

## Ensimm√§inen teko√§lykyselysi

Aloitetaan perusteista luomalla ensimm√§inen teko√§lysovellus, joka l√§hett√§√§ kysymyksen ja saa vastauksen. Kuten Arkhimedes, joka l√∂ysi syrj√§ytymisen periaatteen kylvyss√§√§n, joskus yksinkertaisimmat havainnot johtavat voimakkaimpiin oivalluksiin ‚Äì ja kehykset tekev√§t n√§m√§ oivallukset helposti saavutettaviksi.

### LangChainin k√§ytt√∂√∂notto GitHub-mallien kanssa

K√§yt√§mme LangChainia yhdist√§√§ksemme GitHub-malleihin, mik√§ on aika siisti√§, koska se antaa sinulle ilmaisen p√§√§syn erilaisiin teko√§lymalleihin. Parasta? Tarvitset vain muutaman yksinkertaisen konfiguraatioparametrin aloittaaksesi:

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

# Send a simple prompt
response = llm.invoke("What's the capital of France?")
print(response.content)
```

**Mit√§ t√§ss√§ tapahtuu:**
- **Luo** LangChain-asiakkaan `ChatOpenAI`-luokan avulla ‚Äì t√§m√§ on porttisi teko√§lyyn!
- **Konfiguroi** yhteyden GitHub-malleihin autentikointitunnuksellasi
- **M√§√§ritt√§√§** k√§ytett√§v√§n teko√§lymallin (`gpt-4o-mini`) ‚Äì ajattele t√§t√§ teko√§lyavustajasi valintana
- **L√§hett√§√§** kysymyksesi `invoke()`-metodin avulla ‚Äì t√§ss√§ tapahtuu taikuus
- **Poimii** ja n√§ytt√§√§ vastauksen ‚Äì ja voil√†, keskustelet teko√§lyn kanssa!

> üîß **Asennusvinkki**: Jos k√§yt√§t GitHub Codespacesia, sinulla on onnea ‚Äì `GITHUB_TOKEN` on jo asetettu! Ty√∂skenteletk√∂ paikallisesti? Ei h√§t√§√§, sinun tarvitsee vain luoda henkil√∂kohtainen p√§√§sytunnus oikeilla k√§ytt√∂oikeuksilla.

**Odotettu tulos:**
```text
The capital of France is Paris.
```

```mermaid
sequenceDiagram
    participant App as Your Python App
    participant LC as LangChain
    participant GM as GitHub Models
    participant AI as GPT-4o-mini
    
    App->>LC: llm.invoke("What's the capital of France?")
    LC->>GM: HTTP request with prompt
    GM->>AI: Process prompt
    AI->>GM: Generated response
    GM->>LC: Return response
    LC->>App: response.content
```

## Keskustelevan teko√§lyn rakentaminen

Ensimm√§inen esimerkki osoittaa perusteet, mutta se on vain yksi vaihto ‚Äì kysyt kysymyksen, saat vastauksen, ja siin√§ se. Todellisissa sovelluksissa haluat, ett√§ teko√§ly muistaa, mist√§ olette keskustelleet, kuten Watson ja Holmes rakensivat tutkimuskeskustelujaan ajan my√∂t√§.

T√§ss√§ LangChain on erityisen hy√∂dyllinen. Se tarjoaa erilaisia viestityyppej√§, jotka auttavat j√§sent√§m√§√§n keskusteluja ja antavat sinulle mahdollisuuden antaa teko√§lylle persoonallisuuden. Rakennat keskustelukokemuksia, jotka s√§ilytt√§v√§t kontekstin ja luonteen.

### Viestityyppien ymm√§rt√§minen

Ajattele n√§it√§ viestityyppej√§ eri "hattuina", joita keskustelun osallistujat k√§ytt√§v√§t. LangChain k√§ytt√§√§ erilaisia viestiluokkia pit√§√§kseen kirjaa siit√§, kuka sanoo mit√§:

| Viestityyppi | Tarkoitus | Esimerkkik√§ytt√∂ |
|--------------|-----------|-----------------|
| `SystemMessage` | M√§√§ritt√§√§ teko√§lyn persoonallisuuden ja k√§ytt√§ytymisen | "Olet avulias koodausavustaja" |
| `HumanMessage` | Edustaa k√§ytt√§j√§n sy√∂tett√§ | "Selit√§, miten funktiot toimivat" |
| `AIMessage` | Tallentaa teko√§lyn vastaukset | Aiemmat teko√§lyn vastaukset keskustelussa |

### Ensimm√§isen keskustelun luominen

Luodaan keskustelu, jossa teko√§ly ottaa tietyn roolin. Annetaan sen esitt√§√§ kapteeni Picardia ‚Äì hahmoa, joka tunnetaan diplomaattisesta viisaudestaan ja johtajuudestaan:

```python
messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]
```

**T√§m√§n keskustelun asetusten purkaminen:**
- **M√§√§ritt√§√§** teko√§lyn roolin ja persoonallisuuden `SystemMessage`-viestin kautta
- **Tarjoaa** k√§ytt√§j√§n alkuper√§isen kyselyn `HumanMessage`-viestin kautta
- **Luo** perustan monivaiheiselle keskustelulle

Koko koodi t√§lle esimerkille n√§ytt√§√§ t√§lt√§:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)
print(response.content)
```

N√§et tuloksen, joka n√§ytt√§√§ t√§lt√§:

```text
I am Captain Jean-Luc Picard, the commanding officer of the USS Enterprise (NCC-1701-D), a starship in the United Federation of Planets. My primary mission is to explore new worlds, seek out new life and new civilizations, and boldly go where no one has gone before. 

I believe in the importance of diplomacy, reason, and the pursuit of knowledge. My crew is diverse and skilled, and we often face challenges that test our resolve, ethics, and ingenuity. Throughout my career, I have encountered numerous species, grappled with complex moral dilemmas, and have consistently sought peaceful solutions to conflicts.

I hold the ideals of the Federation close to my heart, believing in the importance of cooperation, understanding, and respect for all sentient beings. My experiences have shaped my leadership style, and I strive to be a thoughtful and just captain. How may I assist you further?
```

Keskustelun jatkuvuuden yll√§pit√§miseksi (sen sijaan, ett√§ konteksti nollataan joka kerta), sinun t√§ytyy lis√§t√§ vastaukset viestilistaan. Kuten suulliset perinteet, jotka s√§ilyttiv√§t tarinoita sukupolvien ajan, t√§m√§ l√§hestymistapa rakentaa pysyv√§n muistin:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

messages = [
    SystemMessage(content="You are Captain Picard of the Starship Enterprise"),
    HumanMessage(content="Tell me about you"),
]


# works
response  = llm.invoke(messages)

print(response.content)

print("---- Next ----")

messages.append(response)
messages.append(HumanMessage(content="Now that I know about you, I'm Chris, can I be in your crew?"))

response  = llm.invoke(messages)

print(response.content)

```

Aika siisti√§, eik√∂? T√§ss√§ tapahtuu se, ett√§ kutsumme LLM:√§√§ kahdesti ‚Äì ensin vain alkuper√§isill√§ kahdella viestill√§, mutta sitten uudelleen koko keskusteluhistorian kanssa. Se on kuin teko√§ly todella seuraisi keskusteluamme!

Kun suoritat t√§m√§n koodin, saat toisen vastauksen, joka kuulostaa suunnilleen t√§lt√§:

```text
Welcome aboard, Chris! It's always a pleasure to meet those who share a passion for exploration and discovery. While I cannot formally offer you a position on the Enterprise right now, I encourage you to pursue your aspirations. We are always in need of talented individuals with diverse skills and backgrounds. 

If you are interested in space exploration, consider education and training in the sciences, engineering, or diplomacy. The values of curiosity, resilience, and teamwork are crucial in Starfleet. Should you ever find yourself on a starship, remember to uphold the principles of the Federation: peace, understanding, and respect for all beings. Your journey can lead you to remarkable adventures, whether in the stars or on the ground. Engage!
```

Otan tuon ehk√§-vastauksena ;)

## Vastausten suoratoisto

Oletko koskaan huomannut, kuinka ChatGPT "kirjoittaa" vastauksiaan reaaliajassa? Se on suoratoistoa toiminnassa. Kuten taitavan kalligrafin ty√∂skentely√§ katsellessa ‚Äì kun kirjaimet ilmestyv√§t viiva kerrallaan sen sijaan, ett√§ ne materialisoituisivat heti ‚Äì suoratoisto tekee vuorovaikutuksesta luonnollisemman ja tarjoaa v√§lit√∂nt√§ palautetta.

### Suoratoiston toteuttaminen LangChainilla

```python
from langchain_openai import ChatOpenAI
import os

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
    streaming=True
)

# Stream the response
for chunk in llm.stream("Write a short story about a robot learning to code"):
    print(chunk.content, end="", flush=True)
```

**Miksi suoratoisto on mahtavaa:**
- **N√§ytt√§√§** sis√§ll√∂n sen luomisen aikana ‚Äì ei en√§√§ kiusallista odottelua!
- **Saa** k√§ytt√§j√§t tuntemaan, ett√§ jotain tapahtuu
- **Tuntuu** nopeammalta, vaikka teknisesti ei olisikaan
- **Antaa** k√§ytt√§jien alkaa lukea, kun teko√§ly viel√§ "ajattelee"

> üí° **K√§ytt√§j√§kokemusvinkki**: Suoratoisto loistaa erityisesti, kun k√§sittelet pidempi√§ vastauksia, kuten koodiselityksi√§, luovaa kirjoittamista tai yksityiskohtaisia oppaita. K√§ytt√§j√§si rakastavat n√§hd√§ edistyst√§ sen sijaan, ett√§ tuijottaisivat tyhj√§√§ ruutua!

## Kehotemallit

Kehotemallit toimivat kuin retoriset rakenteet klassisessa puhetaidossa ‚Äì ajattele, kuinka Cicero mukautti puhetyylins√§ eri yleis√∂ille s√§ilytt√§en saman vakuuttavan rakenteen. Niiden avulla voit luoda uudelleenk√§ytett√§vi√§ kehotteita, joissa voit vaihtaa eri tietoja ilman, ett√§ sinun tarvitsee kirjoittaa kaikkea uudelleen. Kun malli on asetettu, t√§yt√§t vain muuttujat tarvittavilla arvoilla.

### Uudelleenk√§ytett√§vien kehotteiden luominen

```python
from langchain_core.prompts import ChatPromptTemplate

# Define a template for code explanations
template = ChatPromptTemplate.from_messages([
    ("system", "You are an expert programming instructor. Explain concepts clearly with examples."),
    ("human", "Explain {concept} in {language} with a practical example for {skill_level} developers")
])

# Use the template with different values
questions = [
    {"concept": "functions", "language": "JavaScript", "skill_level": "beginner"},
    {"concept": "classes", "language": "Python", "skill_level": "intermediate"},
    {"concept": "async/await", "language": "JavaScript", "skill_level": "advanced"}
]

for question in questions:
    prompt = template.format_messages(**question)
    response = llm.invoke(prompt)
    print(f"Topic: {question['concept']}\n{response.content}\n---\n")
```

**Miksi rakastat mallien k√§ytt√∂√§:**
- **Pit√§√§** kehotteesi johdonmukaisina koko sovelluksessa
- **Ei en√§√§** sotkuista merkkijonojen yhdistely√§ ‚Äì vain siistej√§, yksinkertaisia muuttujia
- **Teko√§lysi** k√§ytt√§ytyy ennustettavasti, koska rakenne pysyy samana
- **P√§ivitykset** ovat helppoja ‚Äì muuta mallia kerran, ja se on korjattu kaikkialla

## J√§sennelty ulostulo

Oletko koskaan turhautunut yritt√§ess√§si j√§sent√§√§ teko√§lyn vastauksia, jotka palaavat j√§sent√§m√§tt√∂m√§n√§ tekstin√§? J√§sennelty ulostulo on kuin opettaisit teko√§ly√§ noudattamaan systemaattista l√§hestymistapaa, kuten Linnaeus k√§ytti biologisessa luokittelussa ‚Äì j√§rjestelm√§llist√§, ennustettavaa ja helppoa ty√∂st√§√§. Voit pyyt√§√§ JSON-muotoa, tiettyj√§ tietorakenteita tai mit√§ tahansa tarvitsemaasi muotoa.

### Ulostulokaavioiden m√§√§ritt√§minen

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

class CodeReview(BaseModel):
    score: int = Field(description="Code quality score from 1-10")
    strengths: list[str] = Field(description="List of code strengths")
    improvements: list[str] = Field(description="List of suggested improvements")
    overall_feedback: str = Field(description="Summary feedback")

# Set up the parser
parser = JsonOutputParser(pydantic_object=CodeReview)

# Create prompt with format instructions
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a code reviewer. {format_instructions}"),
    ("human", "Review this code: {code}")
])

# Format the prompt with instructions
chain = prompt | llm | parser

# Get structured response
code_sample = """
def calculate_average(numbers):
    return sum(numbers) / len(numbers)
"""

result = chain.invoke({
    "code": code_sample,
    "format_instructions": parser.get_format_instructions()
})

print(f"Score: {result['score']}")
print(f"Strengths: {', '.join(result['strengths'])}")
```

**Miksi j√§sennelty ulostulo on mullistava:**
- **Ei en√§√§** arvailua, miss√§ muodossa vastaus tulee ‚Äì se on aina johdonmukainen
- **Sopii** suoraan tietokantoihisi ja API-rajapintoihisi ilman lis√§ty√∂t√§
- **Havaitsee** oudot teko√§lyvastaukset ennen kuin ne rikkovat sovelluksesi
- **Tekee** koodistasi siistimm√§n, koska tied√§t tarkalleen, mit√§ k√§sittelet

## Ty√∂kalujen k√§ytt√∂

Nyt p√§√§semme yhteen tehokkaimmista ominaisuuksista: ty√∂kalut. N√§in annat teko√§lyllesi k√§yt√§nn√∂n kykyj√§ keskustelun ulkopuolella. Kuten keskiaikaiset killat kehittiv√§t erikoisty√∂kaluja tiettyihin k√§sity√∂aloihin, voit varustaa teko√§lysi keskittyneill√§ v√§lineill√§. Kuvailet, mitk√§ ty√∂kalut ovat k√§ytett√§viss√§, ja kun joku pyyt√§√§ jotain vastaavaa, teko√§ly voi toimia.

### Pythonin k√§ytt√∂

Lis√§t√§√§n joitakin ty√∂kaluja n√§in:

```python
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}
```

Mit√§ t√§ss√§ tapahtuu? Luomme ty√∂kalulle nimelt√§ `add` suunnitelman. Perim√§ll√§ `TypedDict`-luokasta ja k√§ytt√§m√§ll√§ hienoja `Annotated`-tyyppej√§ `a` ja `b`-kentille, annamme LLM:lle selke√§n kuvan siit√§, mit√§ t√§m√§ ty√∂kalu tekee ja mit√§ se tarvitsee. `functions`-sanakirja on kuin ty√∂kalupakkimme ‚Äì se kertoo koodillemme tarkalleen, mit√§ tehd√§, kun teko√§ly p√§√§tt√§√§ k√§ytt√§√§ tietty√§ ty√∂kalua.

Katsotaanpa, kuinka kutsumme LLM:√§√§ t√§m√§n ty√∂kalun kanssa seuraavaksi:

```python
llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)
```

T√§ss√§ kutsumme `bind_tools`-metodia `tools`-taulukolla, ja n√§in LLM `llm_with_tools` tuntee t√§m√§n ty√∂kalun.

K√§ytt√§√§ksemme t√§t√§ uutta LLM:√§√§ voimme kirjoittaa seuraavan koodin:

```python
query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Kun kutsumme `invoke`-metodia t√§h√§n uuteen LLM:√§√§n, jolla on ty√∂kaluja, ominaisuus `tool_calls` saattaa t√§ytty√§. Jos n√§in tapahtuu, tunnistetut ty√∂kalut sis√§lt√§v√§t `name`- ja `args`-ominaisuudet, jotka tunnistavat, mit√§ ty√∂kalua tulisi k√§ytt√§√§ ja mill√§ argumenteilla. Koko koodi n√§ytt√§√§ t√§lt√§:

```python
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

tools = [add]

functions = {
    "add": lambda a, b: a + b
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "What is 3 + 12?"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

Kun suoritat t√§m√§n koodin, n√§et tuloksen, joka n√§ytt√§√§ t√§lt√§:

```text
TOOL CALL:  15
CONTENT: 
```

Teko√§ly tutki "Mik√§ on 3 + 12" ja tunnisti t√§m√§n teht√§v√§ksi `add`-ty√∂kalulle. Kuten taitava kirjastonhoitaja tiet√§√§, mihin viitteeseen turvautua kysymyksen tyypin perusteella, teko√§ly teki t√§m√§n p√§√§telm√§n ty√∂kalun nimen, kuvauksen ja kentt√§m√§√§rittelyjen perusteella. Tulos 15 tulee `functions`-sanakirjastamme, joka suorittaa ty√∂kalun:

```python
print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
```

### Mielenkiintoisempi ty√∂kalu, joka kutsuu verkkosovellusliittym√§√§

Lukujen lis√§√§minen havainnollistaa konseptia, mutta todelliset ty√∂kalut suorittavat yleens√§ monimutkaisempia operaatioita, kuten verkkosovellusliittymien kutsumista. Laajennetaan esimerkkiamme niin, ett√§ teko√§ly hakee sis√§lt√∂√§ internetist√§ ‚Äì kuten kuinka lenn√§tinoperaattorit kerran yhdistiv√§t kaukaisia paikkoja:

```python
class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

query = "Tell me a joke about animals"

# the rest of the code is the same
```

Kun suoritat t√§m√§n koodin, saat vastauksen, joka sanoo jotain t√§llaista:

```text
TOOL CALL:  Chuck Norris once rode a nine foot grizzly bear through an automatic car wash, instead of taking a shower.
CONTENT:  
```

T√§ss√§ on koodi kokonaisuudessaan:

```python
from langchain_openai import ChatOpenAI
import requests
import os
from typing_extensions import Annotated, TypedDict

class add(TypedDict):
    """Add two integers."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    a: Annotated[int, ..., "First integer"]
    b: Annotated[int, ..., "Second integer"]

class joke(TypedDict):
    """Tell a joke."""

    # Annotations must have the type and can optionally include a default value and description (in that order).
    category: Annotated[str, ..., "The joke category"]

tools = [add, joke]

def get_joke(category: str) -> str:
    response = requests.get(f"https://api.chucknorris.io/jokes/random?category={category}", headers={"Accept": "application/json"})
    if response.status_code == 200:
        return response.json().get("value", f"Here's a {category} joke!")
    return f"Here's a {category} joke!"

functions = {
    "add": lambda a, b: a + b,
    "joke": lambda category: get_joke(category)
}

llm = ChatOpenAI(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="openai/gpt-4o-mini",
)

llm_with_tools = llm.bind_tools(tools)

query = "Tell me a joke about animals"

res = llm_with_tools.invoke(query)
if(res.tool_calls):
    for tool in res.tool_calls:
        # print("TOOL CALL: ", tool)
        print("TOOL CALL: ", functions[tool["name"]](../../../10-ai-framework-project/**tool["args"]))
print("CONTENT: ",res.content)
```

## Upotukset ja dokumenttien k√§sittely

Upotukset edustavat yht√§ modernin teko√§lyn elegantimmista ratkaisuista. Kuvittele, ett√§ voisit ottaa mink√§ tahansa tekstin ja muuttaa sen numeerisiksi koordinaateiksi, jotka vangitsevat sen merkityksen. Juuri n√§in upotukset toimivat ‚Äì ne muuntavat tekstin pisteiksi moniulotteisessa avaruudessa, jossa samankaltaiset k√§sitteet ryhmittyv√§t yhteen. Se on kuin ideakoordinaatistoj√§rjestelm√§, joka muistuttaa, kuinka Mendelejev j√§rjesti jaksollisen j√§rjestelm√§n atomisten ominaisuuksien mukaan.

### Upotusten luominen ja k√§ytt√∂

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter

# Initialize embeddings
embeddings = OpenAIEmbeddings(
    api_key=os.environ["GITHUB_TOKEN"],
    base_url="https://models.github.ai/inference",
    model="text-embedding-3-small"
)

# Load and split documents
loader = TextLoader("documentation.txt")
documents = loader.load()

text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(texts, embeddings)

# Perform similarity search
query = "How do I handle user authentication?"
similar_docs = vectorstore.similarity_search(query, k=3)

for doc in similar_docs:
    print(f"Relevant content: {doc.page_content[:200]}...")
```

### Dokumenttien lataajat eri formaateille

```python
from langchain_community.document_loaders import (
    PyPDFLoader,
    CSVLoader,
    JSONLoader,
    WebBaseLoader
)

# Load different document types
pdf_loader = PyPDFLoader("manual.pdf")
csv_loader = CSVLoader("data.csv")
json_loader = JSONLoader("config.json")
web_loader = WebBaseLoader("https://example.com/docs")

# Process all documents
all_documents = []
for loader in [pdf_loader, csv_loader, json_loader, web_loader]:
    docs = loader.load()
    all_documents.extend(docs)
```

**Mit√§ voit tehd√§ upotuksilla:**
- **Rakenna** haku, joka todella ymm√§rt√§√§, mit√§ tarkoitat, ei vain avainsanoja
- **Luo** teko√§ly, joka voi vastata kysymyksiin dokumenteistasi
- **Tee** suositusj√§rjestelmi√§, jotka ehdottavat todella relevanttia sis√§lt√∂√§
- **J√§rjest√§** ja luokittele sis√§lt√∂si automaattisesti

## T√§ydellisen teko√§lysovelluksen rakentaminen

Nyt integro
3. **Personoitu oppiminen**: K√§yt√§ j√§rjestelm√§viestej√§ mukauttamaan vastauksia eri taitotasoille  
4. **Vastausten muotoilu**: Toteuta rakenteellinen ulostulo visailukysymyksille  

### Toteutusvaiheet  

**Vaihe 1: Ymp√§rist√∂n asennus**  
```bash
pip install langchain langchain-openai
```
  
**Vaihe 2: Perustoiminnallisuus keskustelulle**  
- Luo `StudyAssistant`-luokka  
- Toteuta keskustelumuisti  
- Lis√§√§ persoonallisuusasetukset opetustukea varten  

**Vaihe 3: Lis√§√§ opetusv√§lineet**  
- **Koodin selitys**: Jakaa koodin ymm√§rrett√§viin osiin  
- **Visailugeneraattori**: Luo kysymyksi√§ ohjelmointikonsepteista  
- **Edistymisen seuranta**: Seuraa k√§siteltyj√§ aiheita  

**Vaihe 4: Parannellut ominaisuudet (valinnainen)**  
- Toteuta suoratoistovastaukset paremman k√§ytt√§j√§kokemuksen takaamiseksi  
- Lis√§√§ dokumenttien lataus kurssimateriaalien sis√§llytt√§miseksi  
- Luo upotuksia sis√§lt√∂jen samankaltaisuuteen perustuvaa hakua varten  

### Arviointikriteerit  

| Ominaisuus | Erinomainen (4) | Hyv√§ (3) | Tyydytt√§v√§ (2) | Parannettavaa (1) |  
|------------|-----------------|----------|----------------|-------------------|  
| **Keskustelun kulku** | Luonnolliset, kontekstitietoiset vastaukset | Hyv√§ kontekstin s√§ilytt√§minen | Peruskeskustelu | Ei muistia vaihdoista |  
| **Ty√∂kalujen integrointi** | Useita hy√∂dyllisi√§ ty√∂kaluja toimivat saumattomasti | 2+ ty√∂kalua toteutettu oikein | 1-2 perusty√∂kalua | Ty√∂kalut eiv√§t toimi |  
| **Koodin laatu** | Siisti, hyvin dokumentoitu, virheenk√§sittely | Hyv√§ rakenne, jonkin verran dokumentointia | Perustoiminnallisuus toimii | Huono rakenne, ei virheenk√§sittely√§ |  
| **Opetuksellinen arvo** | Todella hy√∂dyllinen oppimiseen, mukautuva | Hyv√§ oppimistuki | Perusselitykset | Rajoitettu opetuksellinen hy√∂ty |  

### Esimerkkikoodirakenne  

```python
class StudyAssistant:
    def __init__(self, skill_level="beginner"):
        # Initialize LLM, tools, and conversation memory
        pass
    
    def explain_code(self, code, language):
        # Tool: Explain how code works
        pass
    
    def generate_quiz(self, topic, difficulty):
        # Tool: Create practice questions
        pass
    
    def chat(self, user_input):
        # Main conversation interface
        pass

# Example usage
assistant = StudyAssistant(skill_level="intermediate")
response = assistant.chat("Explain how Python functions work")
```
  
**Bonushaasteet:**  
- Lis√§√§ √§√§ni sis√§√§n/ulos -ominaisuudet  
- Toteuta verkkok√§ytt√∂liittym√§ Streamlitin tai Flaskin avulla  
- Luo tietopohja kurssimateriaaleista upotusten avulla  
- Lis√§√§ edistymisen seuranta ja personoidut oppimispolut  

## Yhteenveto  

üéâ Olet nyt hallinnut AI-kehyskehityksen perusteet ja oppinut rakentamaan kehittyneit√§ AI-sovelluksia LangChainin avulla. Kuten kattavan oppisopimuskoulutuksen suorittanut, olet hankkinut merkitt√§v√§n ty√∂kalupakin taitoja. Katsotaanpa, mit√§ olet saavuttanut.  

### Mit√§ olet oppinut  

**Kehyksen perusk√§sitteet:**  
- **Kehyksen edut**: Ymm√§rrys siit√§, milloin valita kehykset suoran API-kutsun sijaan  
- **LangChainin perusteet**: AI-malliyhteyksien asennus ja konfigurointi  
- **Viestityypit**: `SystemMessage`, `HumanMessage` ja `AIMessage` rakenteellisiin keskusteluihin  

**Kehittyneet ominaisuudet:**  
- **Ty√∂kalujen kutsuminen**: Mukautettujen ty√∂kalujen luominen ja integrointi AI:n kykyjen parantamiseksi  
- **Keskustelumuisti**: Kontekstin s√§ilytt√§minen useiden keskustelukierrosten ajan  
- **Suoratoistovastaukset**: Reaaliaikaisen vastaustoimituksen toteuttaminen  
- **Kehotemallit**: Uudelleenk√§ytett√§vien, dynaamisten kehotteiden rakentaminen  
- **Rakenteellinen ulostulo**: Johdonmukaisten, j√§sennett√§vien AI-vastausten varmistaminen  
- **Upotukset**: Semanttisen haun ja dokumenttien k√§sittelyominaisuuksien luominen  

**K√§yt√§nn√∂n sovellukset:**  
- **T√§ydellisten sovellusten rakentaminen**: Useiden ominaisuuksien yhdist√§minen tuotantovalmiisiin sovelluksiin  
- **Virheenk√§sittely**: Vankan virheiden hallinnan ja validoinnin toteuttaminen  
- **Ty√∂kalujen integrointi**: Mukautettujen ty√∂kalujen luominen AI:n kykyjen laajentamiseksi  

### Keskeiset opit  

> üéØ **Muista**: AI-kehykset, kuten LangChain, ovat k√§yt√§nn√∂ss√§ monimutkaisuutta piilottavia, ominaisuuksilla t√§ytettyj√§ parhaita yst√§vi√§si. Ne ovat t√§ydellisi√§, kun tarvitset keskustelumuistia, ty√∂kalujen kutsumista tai haluat ty√∂skennell√§ useiden AI-mallien kanssa menett√§m√§tt√§ j√§rke√§si.  

**P√§√§t√∂ksentekokehys AI-integraatiolle:**  

```mermaid
flowchart TD
    A[AI Integration Need] --> B{Simple single query?}
    B -->|Yes| C[Direct API calls]
    B -->|No| D{Need conversation memory?}
    D -->|No| E[SDK Integration]
    D -->|Yes| F{Need tools or complex features?}
    F -->|No| G[Framework with basic setup]
    F -->|Yes| H[Full framework implementation]
    
    C --> I[HTTP requests, minimal dependencies]
    E --> J[Provider SDK, model-specific]
    G --> K[LangChain basic chat]
    H --> L[LangChain with tools, memory, agents]
```
  
### Mihin t√§st√§ eteenp√§in?  

**Aloita rakentaminen heti:**  
- Hy√∂dynn√§ n√§it√§ k√§sitteit√§ ja rakenna jotain, mik√§ innostaa SINUA!  
- Kokeile erilaisia AI-malleja LangChainin avulla - se on kuin AI-mallien leikkikentt√§  
- Luo ty√∂kaluja, jotka ratkaisevat todellisia ongelmia ty√∂ss√§si tai projekteissasi  

**Valmis seuraavalle tasolle?**  
- **AI-agentit**: Rakenna AI-j√§rjestelmi√§, jotka voivat suunnitella ja toteuttaa monimutkaisia teht√§vi√§ itsen√§isesti  
- **RAG (Retrieval-Augmented Generation)**: Yhdist√§ AI omiin tietopohjiisi supertehokkaiden sovellusten luomiseksi  
- **Monimodaalinen AI**: Ty√∂skentele tekstin, kuvien ja √§√§nen kanssa yhdess√§ - mahdollisuudet ovat rajattomat!  
- **Tuotantok√§ytt√∂√∂n ottaminen**: Opi skaalaamaan AI-sovelluksesi ja seuraamaan niit√§ tosiel√§m√§ss√§  

**Liity yhteis√∂√∂n:**  
- LangChain-yhteis√∂ on loistava pysy√§ksesi ajan tasalla ja oppiaksesi parhaita k√§yt√§nt√∂j√§  
- GitHub Models tarjoaa p√§√§syn huippuluokan AI-ominaisuuksiin - t√§ydellinen kokeiluun  
- Jatka harjoittelua eri k√§ytt√∂tapauksilla - jokainen projekti opettaa sinulle jotain uutta  

Nyt sinulla on tiedot rakentaa √§lykk√§it√§, keskustelukykyisi√§ sovelluksia, jotka voivat auttaa ihmisi√§ ratkaisemaan todellisia ongelmia. Kuten renessanssin k√§sity√∂l√§iset, jotka yhdistiv√§t taiteellisen vision tekniseen taitoon, voit nyt yhdist√§√§ AI-kyvyt k√§yt√§nn√∂n sovelluksiin. Kysymys kuuluu: mit√§ sin√§ luot? üöÄ  

## GitHub Copilot Agent -haaste üöÄ  

K√§yt√§ Agent-tilaa suorittaaksesi seuraavan haasteen:  

**Kuvaus:** Rakenna kehittynyt AI-pohjainen koodin tarkistusassistentti, joka yhdist√§√§ useita LangChain-ominaisuuksia, mukaan lukien ty√∂kalujen kutsuminen, rakenteellinen ulostulo ja keskustelumuisti, tarjotakseen kattavaa palautetta koodin l√§hetyksist√§.  

**Kehote:** Luo CodeReviewAssistant-luokka, joka toteuttaa:  
1. Ty√∂kalu koodin monimutkaisuuden analysointiin ja parannusehdotusten antamiseen  
2. Ty√∂kalu koodin tarkistamiseen parhaita k√§yt√§nt√∂j√§ vastaan  
3. Rakenteellinen ulostulo Pydantic-mallien avulla johdonmukaisen tarkistusmuodon varmistamiseksi  
4. Keskustelumuisti tarkistussessioiden seuraamiseksi  
5. P√§√§asiallinen keskusteluk√§ytt√∂liittym√§, joka voi k√§sitell√§ koodin l√§hetyksi√§ ja tarjota yksityiskohtaista, toimivaa palautetta  

Assistentin tulisi pysty√§ tarkistamaan koodia useilla ohjelmointikielill√§, s√§ilytt√§m√§√§n konteksti useiden koodil√§hetysten v√§lill√§ samassa sessiossa ja tarjoamaan sek√§ yhteenvetopisteit√§ ett√§ yksityiskohtaisia parannusehdotuksia.  

Lis√§tietoja [agent mode](https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode) t√§√§ll√§.  

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.